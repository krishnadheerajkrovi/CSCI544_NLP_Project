{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Freeze all pre-trained parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Add a custom classification layer on top of BERT\n",
    "class CustomBERTModel(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(CustomBERTModel, self).__init__()\n",
    "        self.bert = model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(768, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Load text file and list of words to not predict\n",
    "with open('text_file.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "not_predict = ['word1', 'word2', 'word3']\n",
    "\n",
    "# Tokenize text and convert to input tensors\n",
    "tokens = tokenizer.tokenize(text)\n",
    "tokens = [token if token not in not_predict else '[MASK]' for token in tokens]\n",
    "input_ids = torch.tensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)\n",
    "attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "# Define model and optimizer\n",
    "model = CustomBERTModel(num_labels=len(tokenizer))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Fine-tune model\n",
    "labels = input_ids.clone().detach()\n",
    "labels[labels != tokenizer.mask_token_id] = -100\n",
    "\n",
    "for epoch in range(10):\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    logits = outputs.logits\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch:', epoch, 'Loss:', loss.item())\n",
    "\n",
    "# Generate predictions for text with masked words\n",
    "masked_input_ids = input_ids.clone().detach()\n",
    "masked_input_ids[masked_input_ids == tokenizer.mask_token_id] = 0\n",
    "\n",
    "outputs = model(input_ids=masked_input_ids, attention_mask=attention_mask)\n",
    "predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Convert predictions back to tokens\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(predictions.squeeze())\n",
    "predicted_text = tokenizer.convert_tokens_to_string(predicted_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
