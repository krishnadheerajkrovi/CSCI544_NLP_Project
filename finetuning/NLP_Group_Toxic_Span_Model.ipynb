{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1bY48VF-79SEjZQeAACTKXeuh0vcbchyl","authorship_tag":"ABX9TyOwAl0+bcV9/bHRnwTUy5H4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# Mounting drive, storing file paths\n","from google.colab import drive\n","drive.mount('/content/drive')\n","span_dataset = 'drive/MyDrive/NLP_Project/toxic_spans_data/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cP8Zaw0cun1","executionInfo":{"status":"ok","timestamp":1681168003386,"user_tz":420,"elapsed":17310,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}},"outputId":"5a938d52-3db6-4762-fa2f-cff35b69d72e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"fURZKr74aDdR","executionInfo":{"status":"ok","timestamp":1681168011782,"user_tz":420,"elapsed":8408,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"97213a22-7184-4690-eef9-f7f175fb8694"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import json\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","\n","annotations_df = pd.read_csv(span_dataset + 'annotations.csv')\n","comments_df = pd.read_csv(span_dataset + 'comments.csv')\n","\n","# character-wise, start of spans end of spans\n","spans_df = pd.read_csv(span_dataset + 'spans.csv')"]},{"cell_type":"code","source":["annotations_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"_gKyZZFpeRPU","executionInfo":{"status":"ok","timestamp":1681168011783,"user_tz":420,"elapsed":17,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}},"outputId":"cad21a49-7a19-4ebf-86aa-743c97226d03"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   annotation  comment_id  worker country  all toxic  not toxic\n","0           0     5167187     868     USA      False      False\n","1           1     5167187    1316     USA      False      False\n","2           2     5167187    1295     USA      False       True\n","3           3     5167187    2856     USA      False      False\n","4           4     5521110     418     VEN       True       True"],"text/html":["\n","  <div id=\"df-e322bcd6-855b-4300-a591-4358e2510346\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>annotation</th>\n","      <th>comment_id</th>\n","      <th>worker</th>\n","      <th>country</th>\n","      <th>all toxic</th>\n","      <th>not toxic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>5167187</td>\n","      <td>868</td>\n","      <td>USA</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>5167187</td>\n","      <td>1316</td>\n","      <td>USA</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5167187</td>\n","      <td>1295</td>\n","      <td>USA</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>5167187</td>\n","      <td>2856</td>\n","      <td>USA</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>5521110</td>\n","      <td>418</td>\n","      <td>VEN</td>\n","      <td>True</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e322bcd6-855b-4300-a591-4358e2510346')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e322bcd6-855b-4300-a591-4358e2510346 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e322bcd6-855b-4300-a591-4358e2510346');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["\n","comments_df.head()"],"metadata":{"id":"c5X4T4qUeVtL","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1681168013351,"user_tz":420,"elapsed":18,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}},"outputId":"cc1d93ee-66da-4e77-ba7a-413b8248d303"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   comment_id                                       comment_text\n","0      239607  Yet call out all Muslims for the acts of a few...\n","1      239612  This bitch is nuts. Who would read a book by a...\n","2      240311                                   You're an idiot.\n","3      240400  Nincompoop, that's a nice one! I'm partial to ...\n","4      240461  testing purposes: \\n\\nyou are an idiot and i c..."],"text/html":["\n","  <div id=\"df-707f26f0-d64e-410f-85ad-c9ff17e9403f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_id</th>\n","      <th>comment_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>239607</td>\n","      <td>Yet call out all Muslims for the acts of a few...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>239612</td>\n","      <td>This bitch is nuts. Who would read a book by a...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>240311</td>\n","      <td>You're an idiot.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>240400</td>\n","      <td>Nincompoop, that's a nice one! I'm partial to ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>240461</td>\n","      <td>testing purposes: \\n\\nyou are an idiot and i c...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-707f26f0-d64e-410f-85ad-c9ff17e9403f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-707f26f0-d64e-410f-85ad-c9ff17e9403f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-707f26f0-d64e-410f-85ad-c9ff17e9403f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["spans_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"Jg748PcGey4u","executionInfo":{"status":"ok","timestamp":1681168013352,"user_tz":420,"elapsed":14,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}},"outputId":"31a59f9c-5f8e-4355-c8ae-770dcf6406da"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   annotation    type  start  end\n","0           0  Insult    133  139\n","1           1  Insult     84   92\n","2           1  Insult    118  124\n","3           1  Insult    126  131\n","4           1  Insult    133  147"],"text/html":["\n","  <div id=\"df-3b2a8f7f-d182-456c-a8e2-1cd5a7f70f4b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>annotation</th>\n","      <th>type</th>\n","      <th>start</th>\n","      <th>end</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Insult</td>\n","      <td>133</td>\n","      <td>139</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Insult</td>\n","      <td>84</td>\n","      <td>92</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Insult</td>\n","      <td>118</td>\n","      <td>124</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>Insult</td>\n","      <td>126</td>\n","      <td>131</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>Insult</td>\n","      <td>133</td>\n","      <td>147</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b2a8f7f-d182-456c-a8e2-1cd5a7f70f4b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3b2a8f7f-d182-456c-a8e2-1cd5a7f70f4b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3b2a8f7f-d182-456c-a8e2-1cd5a7f70f4b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# marks each word within the given range as 1 the rest 0 for toxic span classification\n","def mark_ranges(words, ranges):\n","    result = []\n","    current_pos = 0\n","    for word in words:\n","        # Calculate the starting and ending character positions of the current word\n","        word_start = current_pos\n","        word_end = current_pos + len(word)\n","        \n","\n","        # Determine whether the current word falls within any of the specified ranges\n","        in_range = any(start <= word_end and end >= word_start for start, end in ranges)\n","        \n","        # Append the mark for the current word to the result list\n","        result.append(1 if in_range else 0)\n","        \n","        # Update the current position to the end of the current word, including its space\n","        current_pos = word_end + 1\n","    return result"],"metadata":{"id":"CKTdfDvJlgoi","executionInfo":{"status":"ok","timestamp":1681168013352,"user_tz":420,"elapsed":12,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# make comment_id dict\n","def load_embeddings(filename):\n","    word2vec = {}\n","    with open(filename, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            line = line.strip().split()\n","            word = line[0]\n","            embedding = [float(x) for x in line[1:]]\n","            word2vec[word] = np.array(embedding)\n","    return word2vec\n","\n","\n","\n","word2vec = load_embeddings('drive/MyDrive/NLP_Project/glove.6B.100d')\n","word2vec['< unk >'] = np.random.rand(100)\n","# comment_splits = comments_df['comment_text'].apply(lambda x: x.split())\n","\n","word2idx = {word: i for i, word in enumerate(word2vec.keys())}\n","with open('drive/MyDrive/NLP_Project/word_to_idx_Glove.json',\"w\") as f:\n","    json.dump(word2idx,f)"],"metadata":{"id":"OO3z2wjmtW_M","executionInfo":{"status":"ok","timestamp":1681168028015,"user_tz":420,"elapsed":14674,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["word2idx['< unk >']\n","word2vec['< unk >']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ccGA-sSphLd0","executionInfo":{"status":"ok","timestamp":1681168043745,"user_tz":420,"elapsed":1570,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}},"outputId":"4009b6b4-9cc7-4147-ba48-7993bc371e20"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.91177531, 0.75569562, 0.10636393, 0.48018965, 0.80990404,\n","       0.24596056, 0.60122782, 0.65938439, 0.23378749, 0.70775804,\n","       0.67394522, 0.94115042, 0.62494239, 0.16100429, 0.1624047 ,\n","       0.72751045, 0.29704669, 0.55336274, 0.67152149, 0.68846305,\n","       0.12872764, 0.37422038, 0.99836368, 0.56226647, 0.83164647,\n","       0.45659317, 0.12183434, 0.567015  , 0.91668265, 0.48883059,\n","       0.01190737, 0.57272194, 0.74128202, 0.41171716, 0.72144421,\n","       0.29680581, 0.31900721, 0.61752724, 0.57784892, 0.35482662,\n","       0.84738751, 0.22206461, 0.06634975, 0.21313842, 0.72484913,\n","       0.71453575, 0.17790254, 0.43124212, 0.13251101, 0.42631795,\n","       0.35887561, 0.35297643, 0.92477963, 0.33395391, 0.59421651,\n","       0.95059033, 0.39335903, 0.44577459, 0.13858051, 0.19471507,\n","       0.27094732, 0.9802633 , 0.6233674 , 0.54856169, 0.03000612,\n","       0.56906439, 0.09774575, 0.29067296, 0.67796287, 0.69058409,\n","       0.71387961, 0.5826095 , 0.8042706 , 0.58327855, 0.88940805,\n","       0.36049098, 0.71896735, 0.80952987, 0.66893888, 0.23625887,\n","       0.48635181, 0.03122132, 0.58489591, 0.94427167, 0.89524948,\n","       0.7566674 , 0.38096751, 0.87152308, 0.44987763, 0.91262185,\n","       0.52471791, 0.18631901, 0.10659662, 0.51252943, 0.48952699,\n","       0.33499679, 0.10271515, 0.9055119 , 0.97438368, 0.03239098])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["def create_embed_matrix(word2vec, word2idx):\n","    embedding_matrix = np.zeros((len(word2idx), 100))\n","    for i, word in enumerate(word2vec):\n","      embedding_matrix[i] = word2vec[word]\n","    return torch.tensor(embedding_matrix)\n","\n","embedding_matrix = create_embed_matrix(word2vec, word2idx)"],"metadata":{"id":"4g_bcIoVf1Is","executionInfo":{"status":"ok","timestamp":1681168044789,"user_tz":420,"elapsed":1049,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def preprocess_text(text):\n","    # Lowercase the text\n","    text = text.lower()\n","    # Remove punctuation and special characters\n","    text = re.sub(r'[^\\w\\s]', ' ', text)\n","    # Tokenize the text\n","    words = nltk.word_tokenize(text)\n","    # Remove stopwords (optional)\n","    # stop_words = set(stopwords.words('english'))\n","    # words = [word for word in words if word not in stop_words]\n","    # Lemmatize words (optional)\n","    lemmatizer = WordNetLemmatizer()\n","    words = [lemmatizer.lemmatize(word) for word in words]\n","    # Reconstruct the preprocessed text\n","    preprocessed_text = ' '.join(words)\n","\n","    return preprocessed_text"],"metadata":{"id":"y-iwSmBmMZer","executionInfo":{"status":"ok","timestamp":1681168045322,"user_tz":420,"elapsed":7,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# creating a comment2idx dict storing the word splits of comments\n","idx2comment = dict(zip(comments_df['comment_id'], comments_df['comment_text'].apply(lambda x : preprocess_text(x).strip().split())))\n","\n","# storing annotation index as key and list of range values associated with it\n","annotation_range_dict = {}\n","for annotation, start, end in zip(spans_df['annotation'], spans_df['start'], spans_df['end']):\n","    annotation_range_dict.setdefault(annotation, []).append((start, end))\n","\n","# function to map words with embeddings\n","def map_word2vec(words, word2vec):\n","  embeddings = []\n","  for word in words: \n","    if word.lower() in word2vec:\n","      embeddings.append(word2vec[word.lower()])\n","    else:\n","      embeddings.append(word2vec['< unk >'])\n","  return embeddings\n","\n","def map_word2idx(words, word2idx):\n","  indices = []\n","  for word in words:\n","    if word.lower() in word2idx:\n","      indices.append(word2idx[word.lower()])\n","    else:\n","      indices.append(word2idx['< unk >'])\n","  return indices"],"metadata":{"id":"eRRtZRGle_t2","executionInfo":{"status":"ok","timestamp":1681168055916,"user_tz":420,"elapsed":6410,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame({\"annotations\" : annotations_df['annotation'], \"comment_id\" : annotations_df['comment_id']})\n","df['comment_splits'] = df['comment_id'].map(idx2comment)\n","df['range_lists'] = df['annotations'].map(lambda x: annotation_range_dict.get(x, []))\n","df['toxic_spans'] = df.apply(lambda x: mark_ranges(x['comment_splits'], x['range_lists']), axis=1)\n","df['embedding_splits'] = df['comment_splits'].apply(lambda x : map_word2vec(x, word2vec))\n","df['comment_idx'] = df['comment_splits'].apply(lambda x : map_word2idx(x, word2idx))\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"Y7NFrQx3jTI4","executionInfo":{"status":"ok","timestamp":1681168065785,"user_tz":420,"elapsed":9881,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}},"outputId":"fd91ae11-2558-4371-aba4-ee6b1ac6c5b4"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   annotations  comment_id                                     comment_splits  \\\n","0            0     5167187  [that, s, right, they, are, not, normal, and, ...   \n","1            1     5167187  [that, s, right, they, are, not, normal, and, ...   \n","2            2     5167187  [that, s, right, they, are, not, normal, and, ...   \n","3            3     5167187  [that, s, right, they, are, not, normal, and, ...   \n","4            4     5521110  [yep, this, crap, sound, like, it, from, a, li...   \n","\n","                                      range_lists  \\\n","0                                    [(133, 139)]   \n","1  [(84, 92), (118, 124), (126, 131), (133, 147)]   \n","2                        [(118, 131), (133, 147)]   \n","3                                      [(84, 92)]   \n","4                                              []   \n","\n","                                         toxic_spans  \\\n","0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","4                        [0, 0, 0, 0, 0, 0, 0, 0, 0]   \n","\n","                                    embedding_splits  \\\n","0  [[-0.093337, 0.19043, 0.68457, -0.41548, -0.22...   \n","1  [[-0.093337, 0.19043, 0.68457, -0.41548, -0.22...   \n","2  [[-0.093337, 0.19043, 0.68457, -0.41548, -0.22...   \n","3  [[-0.093337, 0.19043, 0.68457, -0.41548, -0.22...   \n","4  [[0.30322, -0.091931, 0.89503, -0.44215, -0.32...   \n","\n","                                         comment_idx  \n","0  [12, 1534, 248, 39, 32, 36, 1973, 5, 41, 913, ...  \n","1  [12, 1534, 248, 39, 32, 36, 1973, 5, 41, 913, ...  \n","2  [12, 1534, 248, 39, 32, 36, 1973, 5, 41, 913, ...  \n","3  [12, 1534, 248, 39, 32, 36, 1973, 5, 41, 913, ...  \n","4    [45370, 37, 35404, 1507, 117, 20, 25, 7, 17543]  "],"text/html":["\n","  <div id=\"df-8e13ccd4-3e23-44ae-a785-34333ff32867\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>annotations</th>\n","      <th>comment_id</th>\n","      <th>comment_splits</th>\n","      <th>range_lists</th>\n","      <th>toxic_spans</th>\n","      <th>embedding_splits</th>\n","      <th>comment_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>5167187</td>\n","      <td>[that, s, right, they, are, not, normal, and, ...</td>\n","      <td>[(133, 139)]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[[-0.093337, 0.19043, 0.68457, -0.41548, -0.22...</td>\n","      <td>[12, 1534, 248, 39, 32, 36, 1973, 5, 41, 913, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>5167187</td>\n","      <td>[that, s, right, they, are, not, normal, and, ...</td>\n","      <td>[(84, 92), (118, 124), (126, 131), (133, 147)]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[[-0.093337, 0.19043, 0.68457, -0.41548, -0.22...</td>\n","      <td>[12, 1534, 248, 39, 32, 36, 1973, 5, 41, 913, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5167187</td>\n","      <td>[that, s, right, they, are, not, normal, and, ...</td>\n","      <td>[(118, 131), (133, 147)]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[[-0.093337, 0.19043, 0.68457, -0.41548, -0.22...</td>\n","      <td>[12, 1534, 248, 39, 32, 36, 1973, 5, 41, 913, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>5167187</td>\n","      <td>[that, s, right, they, are, not, normal, and, ...</td>\n","      <td>[(84, 92)]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[[-0.093337, 0.19043, 0.68457, -0.41548, -0.22...</td>\n","      <td>[12, 1534, 248, 39, 32, 36, 1973, 5, 41, 913, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>5521110</td>\n","      <td>[yep, this, crap, sound, like, it, from, a, li...</td>\n","      <td>[]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","      <td>[[0.30322, -0.091931, 0.89503, -0.44215, -0.32...</td>\n","      <td>[45370, 37, 35404, 1507, 117, 20, 25, 7, 17543]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e13ccd4-3e23-44ae-a785-34333ff32867')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8e13ccd4-3e23-44ae-a785-34333ff32867 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8e13ccd4-3e23-44ae-a785-34333ff32867');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# creating test train splits\n","X = df['comment_idx']\n","y = df['toxic_spans']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n","\n","# Reset the indices of X_train and y_train\n","X_train = X_train.values\n","y_train = y_train.values\n","\n","# Reset the indices of X_test and y_test\n","X_test = X_test.values\n","y_test = y_test.values"],"metadata":{"id":"oPM75k9FDVHM","executionInfo":{"status":"ok","timestamp":1681168065786,"user_tz":420,"elapsed":14,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# setting dataloaders\n","batch_size = 32\n","\n","def pad_collate(batch):\n","    word_lens = torch.tensor([len(seq) for seq,_,_ in batch])\n","    word_pad = pad_sequence([torch.tensor(seq) for seq,_,_ in batch], batch_first=True, padding_value=0)\n","    # experiment with padding value\n","    label_pad = pad_sequence([torch.tensor(labels, dtype=torch.float32) for _,_,labels in batch], batch_first=True, padding_value=0)\n","    return word_pad, word_lens, label_pad\n","\n","class ToxicDataset(Dataset):\n","    def __init__(self, words, labels):\n","        self.words = words\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.words)\n","\n","    def __getitem__(self, idx):\n","        sentence = self.words[idx]\n","        lengths = len(self.words[idx])\n","        labels = self.labels[idx]\n","        return sentence, lengths, labels\n","\n","\n","train_dataloader = DataLoader(ToxicDataset(X_train, y_train), batch_size=batch_size, collate_fn=pad_collate)\n","test_dataloader = DataLoader(ToxicDataset(X_test, y_test), batch_size=batch_size, collate_fn=pad_collate)"],"metadata":{"id":"nuuZGfGFMgC5","executionInfo":{"status":"ok","timestamp":1681168065787,"user_tz":420,"elapsed":14,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class BLSTM_Span_Model(torch.nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(BLSTM_Span_Model, self).__init__()\n","        self.input_dim = embedding_matrix.size()[1]\n","\n","        self.hidden_dim = 256\n","        self.linear_output_dim = 128\n","        self.num_classes = 2\n","        self.dropout_factor = 0.33\n","\n","        self.embedding = torch.nn.Embedding.from_pretrained(embedding_matrix, freeze=False, padding_idx=0)\n","\n","        self.lstm = torch.nn.LSTM(self.input_dim, self.hidden_dim, bidirectional=True, batch_first=True)\n","        self.dropout = torch.nn.Dropout(self.dropout_factor)\n","        self.linear = torch.nn.Linear(self.hidden_dim * 2, self.linear_output_dim)\n","        self.elu = torch.nn.ELU()\n","        self.classifier = torch.nn.Linear(self.linear_output_dim, 1)\n","\n","    def forward(self, x, lengths):\n","        x = self.embedding(x)\n","        x = x.to(torch.float32)\n","        x = torch.nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), enforce_sorted=False, batch_first=True)\n","        x, _ = self.lstm(x)\n","        x, _ = torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n","        x = self.dropout(x)\n","        x = self.linear(x)\n","        x = self.elu(x)\n","        x = self.classifier(x)\n","        return x.squeeze()"],"metadata":{"id":"5mLJqUalTmCS","executionInfo":{"status":"ok","timestamp":1681168065788,"user_tz":420,"elapsed":13,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def train(model, train_dataloader, test_dataloader, epochs, loss_fn, optimizer, scheduler, device):\n","    best_dev_loss = float('inf')\n","    best_train_loss = float('inf')\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for words, lengths, labels in train_dataloader:\n","            optimizer.zero_grad()\n","            words, labels, lengths = words.to(device), labels.to(device), lengths.to(device)\n","            pred = model(words, lengths)\n","            loss = loss_fn(pred, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.detach().item()\n","        model.eval()\n","        test_loss = 0.0\n","        for words, lengths, labels in test_dataloader:\n","            words, labels, lengths = words.to(device), labels.to(device), lengths.to(device)\n","            pred = model(words, lengths)\n","            loss = loss_fn(pred, labels)\n","            test_loss += loss.detach().item()\n","        training_loss = running_loss / len(train_dataloader)\n","        dev_loss = test_loss / len(test_dataloader)\n","        # scheduler.step()\n","\n","        # Saves the model with the lowest training and dev losses for testing purposes\n","        # if training_loss < best_train_loss:\n","        #     torch.save(model, 'best_model_train.pt')\n","        #     best_train_loss = training_loss\n","        #     print(f\"Model Saved with {best_train_loss}\")\n","        # if dev_loss < best_dev_loss:\n","        #     torch.save(model, 'best_model_dev.pt')\n","        #     best_dev_loss = dev_loss\n","\n","        print(f'Epoch {epoch}: Training Loss = {training_loss}, Test Loss = {dev_loss}')\n","\n","        # if test_loss / len(test_dataloader) < best_dev_loss:\n","        #     best_dev_loss = test_loss / len(test_dataloader)\n"],"metadata":{"id":"CpMAR6l3yTmU","executionInfo":{"status":"ok","timestamp":1681168065789,"user_tz":420,"elapsed":13,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def get_balanced_bce_loss(y_train, device):\n","    # Calculate the number of samples in each class\n","    flat_list = np.array([x for y in y_train for x in y])\n","    num_positive = np.sum(flat_list)\n","    num_negative = len(flat_list) - num_positive\n","\n","    # Calculate class weights\n","    weight_for_positive = num_negative / (num_positive + num_negative)\n","    weight_for_negative = num_positive / (num_positive + num_negative)\n","\n","    # Pass the weights to BCEWithLogitsLoss\n","    pos_weight = torch.tensor([weight_for_positive / weight_for_negative], dtype=torch.float32)\n","    print(pos_weight)\n","    balanced_bce_loss = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n","\n","    return balanced_bce_loss"],"metadata":{"id":"OuQtsmzhEvFy","executionInfo":{"status":"ok","timestamp":1681168066293,"user_tz":420,"elapsed":515,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["'''\n","Ideas for improvement\n","- Class weighting, much more negative examples than positive examples\n","- Varying architectures, LSTM based\n","- Varying preprocessing strategies\n","'''\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Training on {device}\")\n","epochs = 50\n","lr = .003\n","\n","blstm_model = BLSTM_Span_Model(embedding_matrix)\n","blstm_model.to(device)\n","optimizer = torch.optim.Adam(blstm_model.parameters(), lr)\n","loss_fn = get_balanced_bce_loss(y_train, device)\n","\n","# not used \n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n","\n","train(blstm_model, train_dataloader, test_dataloader, epochs, loss_fn, optimizer, scheduler, device)\n","torch.save(blstm_model.cpu(), 'drive/MyDrive/NLP_Project/blstm_span_model.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qgCVCuBF4OeV","executionInfo":{"status":"ok","timestamp":1681102053339,"user_tz":420,"elapsed":4465044,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}},"outputId":"4aba25d4-e746-47d1-ec79-27154991df13"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on cuda\n","tensor([15.0522])\n","Epoch 0: Training Loss = 0.31473956718427115, Test Loss = 0.28179820042575465\n","Epoch 1: Training Loss = 0.2632695418215941, Test Loss = 0.2770774563689116\n","Epoch 2: Training Loss = 0.19962051362402933, Test Loss = 0.2909079077992478\n","Epoch 3: Training Loss = 0.16426380576313065, Test Loss = 0.339003836851557\n","Epoch 4: Training Loss = 0.14244134082716112, Test Loss = 0.3572695937680427\n","Epoch 5: Training Loss = 0.12989818540091735, Test Loss = 0.44687661273540513\n","Epoch 6: Training Loss = 0.12127801770021149, Test Loss = 0.4620884959347486\n","Epoch 7: Training Loss = 0.11153995309208672, Test Loss = 0.518740848891658\n","Epoch 8: Training Loss = 0.10614307931574674, Test Loss = 0.5853761541393568\n","Epoch 9: Training Loss = 0.09990778392851152, Test Loss = 0.666905722869535\n","Epoch 10: Training Loss = 0.09589826628429958, Test Loss = 0.7324954799484371\n","Epoch 11: Training Loss = 0.09383061766916236, Test Loss = 0.7083610137196564\n","Epoch 12: Training Loss = 0.087930392774525, Test Loss = 0.6478231733218036\n","Epoch 13: Training Loss = 0.08599240910500831, Test Loss = 0.9471911270261775\n","Epoch 14: Training Loss = 0.0838775976330223, Test Loss = 0.983882387090886\n","Epoch 15: Training Loss = 0.07983156720240482, Test Loss = 0.90653757544139\n","Epoch 16: Training Loss = 0.07810599128240914, Test Loss = 0.775608874074211\n","Epoch 17: Training Loss = 0.07777298285495704, Test Loss = 0.7566526541009425\n","Epoch 18: Training Loss = 0.07750775421680951, Test Loss = 0.9311767685606152\n","Epoch 19: Training Loss = 0.07411675578754227, Test Loss = 1.0872634944488417\n","Epoch 20: Training Loss = 0.07367381814598112, Test Loss = 1.004097148755972\n","Epoch 21: Training Loss = 0.07398397472211028, Test Loss = 0.8952063920925248\n","Epoch 22: Training Loss = 0.07420322197004599, Test Loss = 0.8339690315032584\n","Epoch 23: Training Loss = 0.07142922650597572, Test Loss = 0.7788968910827149\n","Epoch 24: Training Loss = 0.06946526851648419, Test Loss = 1.1543783430622594\n","Epoch 25: Training Loss = 0.07139947085913616, Test Loss = 1.0861424496874335\n","Epoch 26: Training Loss = 0.06966603371509018, Test Loss = 1.1059345376057765\n","Epoch 27: Training Loss = 0.06831815069607992, Test Loss = 1.0144952938482767\n","Epoch 28: Training Loss = 0.06902682530938331, Test Loss = 0.909137034070781\n","Epoch 29: Training Loss = 0.06908249765116367, Test Loss = 1.1242905378823653\n","Epoch 30: Training Loss = 0.06886205774437004, Test Loss = 0.8577567743001923\n","Epoch 31: Training Loss = 0.06914720824648608, Test Loss = 0.8933361381934981\n","Epoch 32: Training Loss = 0.0672169295689852, Test Loss = 1.05372842085972\n","Epoch 33: Training Loss = 0.06786402932554987, Test Loss = 0.9765106985430834\n","Epoch 34: Training Loss = 0.06773305307397119, Test Loss = 0.9140025770889139\n","Epoch 35: Training Loss = 0.06554411774014476, Test Loss = 0.984187845913869\n","Epoch 36: Training Loss = 0.06687650753337333, Test Loss = 0.9571609369346074\n","Epoch 37: Training Loss = 0.0664617756216873, Test Loss = 1.190416217613413\n","Epoch 38: Training Loss = 0.06555240860763512, Test Loss = 1.1504068730896053\n","Epoch 39: Training Loss = 0.06502376358068167, Test Loss = 1.0163225206242739\n","Epoch 40: Training Loss = 0.06636977770254468, Test Loss = 0.9527127261190723\n","Epoch 41: Training Loss = 0.06519154844595564, Test Loss = 1.0437942140226095\n","Epoch 42: Training Loss = 0.06425677675057069, Test Loss = 0.9466280907472832\n","Epoch 43: Training Loss = 0.06509747896356047, Test Loss = 1.0094231524758261\n","Epoch 44: Training Loss = 0.06471982333560114, Test Loss = 0.9174030870199203\n","Epoch 45: Training Loss = 0.06452913372541584, Test Loss = 1.0093059877179704\n","Epoch 46: Training Loss = 0.0642844908716689, Test Loss = 1.0261985539506389\n","Epoch 47: Training Loss = 0.06479798106176075, Test Loss = 1.0234439724860487\n","Epoch 48: Training Loss = 0.0653162177596782, Test Loss = 1.043234799468935\n","Epoch 49: Training Loss = 0.06372017098325358, Test Loss = 1.0431342181169763\n"]}]},{"cell_type":"code","source":["lr = .003\n","model = torch.load('drive/MyDrive/NLP_Project/blstm_span_model.pt')\n","device = torch.device('cpu')\n","optimizer = torch.optim.Adam(model.parameters(), lr)\n","# loss_fn = get_balanced_bce_loss(y_train, device)\n","\n","preds=[]\n","true=[]\n","true2=[]\n","model.eval()\n","for i, (words, lengths, labels) in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        words, lengths, labels = words.to(device),lengths.to(device),labels.to(device)\n","        logits = model(words,lengths).cpu()\n","#         mask = labels>=0 \n","# #         print(labels)\n","#         labels = labels[mask]\n","#         print(\"labels: \",labels)\n","        # logits = logits.permute(0,2,1)[mask].view(-1, tagset_size-1)\n","#         print(\"preds:\", torch.argmax(logits,dim=1))\n","        true += labels.cpu()\n","        true2.extend(labels.cpu().numpy())\n","        # make sure to put it through sigmoid at the end\n","        p = np.round(torch.sigmoid(logits).cpu().detach().numpy())\n","        preds.extend(p)"],"metadata":{"id":"X9vRbuOEVXWi","executionInfo":{"status":"ok","timestamp":1681168357298,"user_tz":420,"elapsed":158331,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["print(f'Accuracy: {accuracy_score(torch.cat(true).numpy(), np.concatenate(preds))}')\n","print(f'F1 Score: {f1_score(torch.cat(true).numpy(), np.concatenate(preds))}')\n","print(f'Recall Score: {recall_score(torch.cat(true).numpy(), np.concatenate(preds))}')\n","print(f'Precision Score: {precision_score(torch.cat(true).numpy(), np.concatenate(preds))}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LR0lJGdJ1k4Y","executionInfo":{"status":"ok","timestamp":1681169258586,"user_tz":420,"elapsed":15220,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}},"outputId":"10121fb5-4b46-4148-fa6e-a0497e420165"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9506490890131787\n","F1 Score: 0.31146241025057214\n","Recall Score: 0.7209410097045034\n","Precision Score: 0.19863953412681323\n"]}]},{"cell_type":"code","source":["preds=[]\n","true=[]\n","true2=[]\n","model.eval()\n","for i, (words, lengths, labels) in enumerate(test_dataloader):\n","        optimizer.zero_grad()\n","        words, lengths, labels = words.to(device),lengths.to(device),labels.to(device)\n","        logits = model(words,lengths).cpu()\n","#         mask = labels>=0 \n","# #         print(labels)\n","#         labels = labels[mask]\n","#         print(\"labels: \",labels)\n","        # logits = logits.permute(0,2,1)[mask].view(-1, tagset_size-1)\n","#         print(\"preds:\", torch.argmax(logits,dim=1))\n","        true += labels.cpu()\n","        true2.extend(labels.cpu().numpy())\n","        # make sure to put it through sigmoid at the end\n","        p = np.round(torch.sigmoid(logits).cpu().detach().numpy())\n","        preds.extend(p)"],"metadata":{"id":"_OhfWGbz5eR5","executionInfo":{"status":"ok","timestamp":1681169344046,"user_tz":420,"elapsed":41891,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["print(f'Accuracy: {accuracy_score(torch.cat(true).numpy(), np.concatenate(preds))}')\n","print(f'F1 Score: {f1_score(torch.cat(true).numpy(), np.concatenate(preds))}')\n","print(f'Recall Score: {recall_score(torch.cat(true).numpy(), np.concatenate(preds))}')\n","print(f'Precision Score: {precision_score(torch.cat(true).numpy(), np.concatenate(preds))}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hODNwGZqCsxW","executionInfo":{"status":"ok","timestamp":1681169347178,"user_tz":420,"elapsed":3152,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}},"outputId":"70431c61-eb60-44bf-be43-bf7077573512"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9423065137752115\n","F1 Score: 0.22933547589991585\n","Recall Score: 0.5627766824150887\n","Precision Score: 0.1440103571700556\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Cztt7GMdDOE_","executionInfo":{"status":"aborted","timestamp":1681097019263,"user_tz":420,"elapsed":5,"user":{"displayName":"Antonio Revilla","userId":"04103202020586531988"}}},"execution_count":null,"outputs":[]}]}