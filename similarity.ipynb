{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sent = pd.read_csv('/Users/venkatasaisumanthsadu/Documents/clg-documents/CSCI544/project/CSCI544_NLP_Project-main/bad_sentences.csv')\n",
    "good_sent = pd.read_csv('/Users/venkatasaisumanthsadu/Documents/clg-documents/CSCI544/project/CSCI544_NLP_Project-main/good_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sent = bad_sent[['comments','labels']]\n",
    "good_sent = good_sent[['comments','labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5769</th>\n",
       "      <td>And none of this white-collar resort prison. T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>This article from last month still mentions th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>an inconsequential person that conspiracy theo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6733</th>\n",
       "      <td>Canons, repeating rifles, warships, and even m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9216</th>\n",
       "      <td>As somebody who has done basically that, it's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12016</th>\n",
       "      <td>There will never be peace with leaders like Bi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12191</th>\n",
       "      <td>Get the fuck out of here they were dickriding ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>You stan hard enough for Bread Cruz to know he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>To be clear, I think he is a scum bad, sex tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>But one of the girls did name his \"co-conspira...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  labels\n",
       "5769   And none of this white-collar resort prison. T...       1\n",
       "4829   This article from last month still mentions th...       1\n",
       "784    an inconsequential person that conspiracy theo...       1\n",
       "6733   Canons, repeating rifles, warships, and even m...       1\n",
       "9216   As somebody who has done basically that, it's ...       1\n",
       "12016  There will never be peace with leaders like Bi...       1\n",
       "12191  Get the fuck out of here they were dickriding ...       1\n",
       "2502   You stan hard enough for Bread Cruz to know he...       1\n",
       "3261   To be clear, I think he is a scum bad, sex tra...       1\n",
       "3277   But one of the girls did name his \"co-conspira...       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_sent = bad_sent.sample(10)\n",
    "bad_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I get this feeling that derailments happen A L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1) pay your workers less than your shareholder...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt; Former US president Barack Obama passed legi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guess the US government is in the process of f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nationalize the rail. This is happening becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14434</th>\n",
       "      <td>eh, sucks for everyone yes, i agree, but it su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14435</th>\n",
       "      <td>Russia does have a larger and higher tech air ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14436</th>\n",
       "      <td>If there's any finalists in the olympics of su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14437</th>\n",
       "      <td>Mostly through reddit and the sources linked, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14438</th>\n",
       "      <td>American intelligence is absolutely crucial to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14439 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  labels\n",
       "0      I get this feeling that derailments happen A L...       1\n",
       "1      1) pay your workers less than your shareholder...       1\n",
       "2      > Former US president Barack Obama passed legi...       1\n",
       "3      Guess the US government is in the process of f...       1\n",
       "4      Nationalize the rail. This is happening becaus...       1\n",
       "...                                                  ...     ...\n",
       "14434  eh, sucks for everyone yes, i agree, but it su...       1\n",
       "14435  Russia does have a larger and higher tech air ...       1\n",
       "14436  If there's any finalists in the olympics of su...       1\n",
       "14437  Mostly through reddit and the sources linked, ...       1\n",
       "14438  American intelligence is absolutely crucial to...       1\n",
       "\n",
       "[14439 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_sent_vectors = []\n",
    "bad_sent_vectors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5769</th>\n",
       "      <td>And none of this white-collar resort prison. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>This article from last month still mentions th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>an inconsequential person that conspiracy theo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6733</th>\n",
       "      <td>Canons, repeating rifles, warships, and even m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9216</th>\n",
       "      <td>As somebody who has done basically that, it's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12016</th>\n",
       "      <td>There will never be peace with leaders like Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12191</th>\n",
       "      <td>Get the fuck out of here they were dickriding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>You stan hard enough for Bread Cruz to know he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>To be clear, I think he is a scum bad, sex tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>But one of the girls did name his \"co-conspira...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments\n",
       "5769   And none of this white-collar resort prison. T...\n",
       "4829   This article from last month still mentions th...\n",
       "784    an inconsequential person that conspiracy theo...\n",
       "6733   Canons, repeating rifles, warships, and even m...\n",
       "9216   As somebody who has done basically that, it's ...\n",
       "12016  There will never be peace with leaders like Bi...\n",
       "12191  Get the fuck out of here they were dickriding ...\n",
       "2502   You stan hard enough for Bread Cruz to know he...\n",
       "3261   To be clear, I think he is a scum bad, sex tra...\n",
       "3277   But one of the girls did name his \"co-conspira..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_sent[['comments']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program to measure the similarity between\n",
    "# two sentences using cosine similarity.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# X = input(\"Enter first string: \").lower()\n",
    "# Y = input(\"Enter second string: \").lower()\n",
    "# X =\"I love horror movies\"\n",
    "# Y =\"Lights out is a horror movie\"\n",
    "\n",
    "# tokenization\n",
    "# for i in range(len(bad_sent)):\n",
    "# \tX_list = word_tokenize(bad_sent)\n",
    "# \tY_list = word_tokenize(Y)\n",
    "\n",
    "for row in bad_sent.itertuples(index = True):\n",
    "\tX_list = word_tokenize(row[1])\n",
    "\tbad_sent_vectors.append(X_list)\n",
    "\n",
    "for good_rows in good_sent.itertuples(index = True):\n",
    "\tY_list = word_tokenize(good_rows[1])\n",
    "\tgood_sent_vectors.append(Y_list)\n",
    "\n",
    "\n",
    "\n",
    "# # sw contains the list of stopwords\n",
    "# sw = stopwords.words('english')\n",
    "# l1 =[];l2 =[]\n",
    "\n",
    "# # remove stop words from the string\n",
    "# X_set = {w for w in X_list if not w in sw}\n",
    "# Y_set = {w for w in Y_list if not w in sw}\n",
    "\n",
    "# form a set containing keywords of both strings\n",
    "rvector = X_set.union(Y_set)\n",
    "for w in rvector:\n",
    "\tif w in X_set: l1.append(1) # create a vector\n",
    "\telse: l1.append(0)\n",
    "\tif w in Y_set: l2.append(1)\n",
    "\telse: l2.append(0)\n",
    "c = 0\n",
    "\n",
    "# cosine formula\n",
    "for i in range(len(rvector)):\n",
    "\t\tc+= l1[i]*l2[i]\n",
    "cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "print(\"similarity: \", cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_comments = []\n",
    "good_comments = []\n",
    "for bad_rows in bad_sent.itertuples(index = True):\n",
    "    bad_comments.append(bad_rows[1])\n",
    "\n",
    "for good_rows in good_sent.itertuples(index = True):\n",
    "    good_comments.append(good_rows[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 446 while Y.shape[1] == 32281",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dz/k6x51lvd2jv050r966v_h2br0000gn/T/ipykernel_18222/824269857.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Calculate the cosine similarity between the two documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcosine_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_matrix_bad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_matrix_good\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cosine similarity:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m             )\n\u001b[1;32m    180\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;34m\"Incompatible dimension for X and Y matrices: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;34m\"X.shape[1] == %d while Y.shape[1] == %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 446 while Y.shape[1] == 32281"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define two sample documents\n",
    "# doc1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "# doc2 = \"A quick brown dog outpaces a quick fox.\"\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Create a matrix of tf-idf scores for the two documents\n",
    "tfidf_matrix_bad = tfidf_vectorizer.fit_transform(bad_comments)\n",
    "tfidf_matrix_good = tfidf_vectorizer.fit_transform(good_comments)\n",
    "\n",
    "# Calculate the cosine similarity between the two documents\n",
    "cosine_sim = cosine_similarity(tfidf_matrix_bad[0], tfidf_matrix_good[0])[0][0]\n",
    "\n",
    "print(\"Cosine similarity:\", cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 446)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_bad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37264, 32281)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_good.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import gensim.downloader as api\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts sentences/reivews to array of list of words for them to be converted into word2vec vectors later.\n",
    "def sentence_to_words(sentences):\n",
    "    result_list = []\n",
    "    for sent in sentences:\n",
    "        result_list.append(utils.simple_preprocess(sent))\n",
    "    \n",
    "    return np.asarray(result_list, dtype=object)\n",
    "\n",
    "# find the average vector for each sentence/review by adding all the vectors of words in a sentence/review and dividing by lenght of the sentence (no of words in sentence/review)\n",
    "def avg_vector(sent, wv):\n",
    "    vector = np.zeros((300,))\n",
    "    if len(sent) != 0:\n",
    "        for word in sent:\n",
    "            if word in wv:\n",
    "                vector = vector + wv[word]\n",
    "\n",
    "        vector = vector / len(sent)\n",
    "    \n",
    "    return vector\n",
    "    \n",
    "# find average vector for each sentence/review in corpus.\n",
    "def review_to_vector(sentences, wv):\n",
    "    result = np.empty((len(sentences), 300), dtype=np.float64)\n",
    "    for i, sent in enumerate(sentences):\n",
    "        result[i] = avg_vector(sent, wv)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bad_wv = sentence_to_words(bad_comments)\n",
    "x_good_wv = sentence_to_words(good_comments)\n",
    "\n",
    "# final vectors for each review\n",
    "x_bad_wv = review_to_vector(x_bad_wv, wv)\n",
    "x_good_wv = review_to_vector(x_good_wv, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.32421875e-05, -5.79566956e-03,  6.52282715e-02,  7.81463623e-02,\n",
       "        3.94836426e-02, -4.98291016e-02, -1.13739014e-02, -1.80725098e-02,\n",
       "        3.69506836e-02,  4.86939430e-02, -6.63986206e-03, -7.82775879e-02,\n",
       "       -2.25708008e-02,  1.13342285e-02, -1.18554688e-01,  4.36798096e-02,\n",
       "       -3.08227539e-04,  8.76579285e-02, -3.88671875e-02, -4.81933594e-02,\n",
       "        1.26296997e-02, -6.93054199e-03,  1.45034790e-03, -2.14038849e-02,\n",
       "        4.86846924e-02, -7.27401733e-02, -7.35023499e-02,  5.01403809e-02,\n",
       "        5.59852600e-02, -1.10107422e-02,  1.79687500e-02,  1.65618896e-02,\n",
       "       -3.38928223e-02,  4.13831711e-02, -2.98271179e-02,  1.99779510e-02,\n",
       "        4.60059166e-02, -2.73864746e-02, -3.16070557e-02,  8.13796997e-02,\n",
       "        5.64331055e-02, -7.00546265e-02,  9.27734375e-02, -3.70697021e-02,\n",
       "       -1.97784424e-02,  1.51748657e-03,  1.61514282e-02,  1.33117676e-02,\n",
       "       -1.86737061e-02,  3.19213867e-02, -4.06494141e-03,  4.25140381e-02,\n",
       "        2.34588623e-02, -2.80151367e-03, -1.86912537e-02, -6.27811432e-02,\n",
       "       -6.71997070e-03, -5.07125854e-02,  2.78264046e-02, -7.07672119e-02,\n",
       "       -4.65103149e-02,  2.03384399e-02, -3.31146240e-02, -2.91076660e-02,\n",
       "       -1.99645996e-02, -8.50219727e-03, -4.68017578e-02,  5.83435059e-02,\n",
       "       -2.65808105e-02,  5.32073975e-02,  5.34881592e-02,  5.82031250e-02,\n",
       "        1.72851562e-02,  3.33801270e-02, -1.00975037e-01, -4.44030762e-02,\n",
       "        5.99914551e-02,  1.17401123e-01,  3.36303711e-02,  3.65722656e-02,\n",
       "        1.72523499e-02, -1.04574966e-01, -3.24268341e-02, -3.62979889e-02,\n",
       "       -5.66761017e-02, -3.78845215e-02, -5.14249802e-02,  1.04162598e-01,\n",
       "        5.86669922e-02, -4.34783936e-02,  5.60424805e-02,  3.99291992e-02,\n",
       "       -5.44860840e-02, -6.35246277e-02, -1.69830322e-02, -6.52526855e-02,\n",
       "        1.11689758e-01, -3.74938965e-02, -1.73492432e-03, -7.18376160e-02,\n",
       "       -6.60790443e-02, -5.77392578e-02,  2.23205566e-02, -2.31887817e-02,\n",
       "       -3.89739990e-02, -4.53887939e-02, -3.27453613e-03, -4.29290771e-02,\n",
       "        6.06079102e-02, -1.10433960e-01, -4.96765137e-02, -6.37359619e-03,\n",
       "       -1.25915527e-02,  6.04660034e-02,  7.66944885e-03,  9.60350037e-03,\n",
       "        7.61878967e-02, -4.23004150e-02,  3.97911072e-02,  7.71850586e-02,\n",
       "       -7.86972046e-02,  1.59729004e-02, -8.14674377e-02,  7.94525146e-03,\n",
       "        5.65299988e-02, -7.33276367e-02,  1.41967773e-02, -5.98449707e-02,\n",
       "        2.55004883e-02,  1.50413513e-02, -2.61505127e-02, -4.13696289e-02,\n",
       "       -7.51708984e-02, -2.35382080e-02, -4.65881348e-02, -6.10054016e-02,\n",
       "       -1.35803223e-02, -1.77001953e-03,  3.91326904e-02,  6.20738983e-02,\n",
       "        3.71261597e-02, -6.85089111e-02, -3.34167480e-03, -2.76794434e-03,\n",
       "        1.30310059e-03,  2.96325684e-02, -6.89636230e-02, -4.50654984e-02,\n",
       "       -4.49508667e-02, -1.37756348e-02,  1.09315491e-01, -2.71125793e-02,\n",
       "       -8.72558594e-02,  3.51882935e-02, -6.73294067e-03, -5.27343750e-03,\n",
       "       -5.97686768e-02, -7.23846436e-02,  8.02230835e-03,  9.09461975e-03,\n",
       "       -6.44531250e-03,  5.79650879e-02,  5.70846558e-02, -8.94165039e-04,\n",
       "       -5.50804138e-02, -3.61389160e-02,  1.80175781e-02, -4.39895630e-02,\n",
       "        5.86242676e-03,  3.07861328e-02, -1.02050781e-01, -5.27984619e-02,\n",
       "       -5.86474419e-02,  1.22924805e-02, -4.77996826e-02, -8.66699219e-04,\n",
       "        7.82958984e-02, -3.18237305e-02, -5.96069336e-02,  2.61039734e-02,\n",
       "       -7.35290527e-02, -4.09172058e-02, -2.44110107e-02,  1.57775879e-03,\n",
       "        1.49589539e-02, -8.23303223e-02,  2.72861481e-02,  4.08502102e-02,\n",
       "        1.04125977e-01,  6.76364899e-02,  3.52973938e-02, -1.06323242e-02,\n",
       "        5.75851440e-02, -2.96127319e-02, -5.57083130e-02,  4.96261597e-02,\n",
       "       -5.43292999e-02,  1.10366821e-02, -5.64994812e-02, -7.87628174e-02,\n",
       "       -7.42874146e-03,  7.37182617e-02,  4.29077148e-02,  1.48967743e-02,\n",
       "        2.99896240e-02,  2.86254883e-03,  1.91040039e-03, -3.66180420e-02,\n",
       "       -8.80432129e-04, -3.77990723e-02, -4.34448242e-02,  3.11538696e-02,\n",
       "        2.52349854e-02,  3.55392456e-02, -8.29467773e-02,  2.02629089e-02,\n",
       "        4.53979492e-02, -2.78434753e-02, -1.16503906e-01, -4.37286377e-02,\n",
       "       -2.59399414e-02,  1.49749756e-02, -2.08423615e-02,  1.52740479e-03,\n",
       "        5.40771484e-02, -5.62927246e-02,  6.76361084e-02,  7.13470459e-02,\n",
       "        5.03845215e-03, -3.96697998e-02,  3.88259888e-02, -1.39077759e-01,\n",
       "       -1.33117676e-02,  3.12164307e-02, -1.00170135e-02,  2.94586182e-02,\n",
       "       -1.56021118e-02,  4.21142578e-03,  9.00817871e-02, -3.89389038e-02,\n",
       "        9.28421021e-02,  3.75030518e-02,  9.06066895e-03, -1.25770569e-01,\n",
       "       -1.94515228e-02,  5.26504517e-03,  2.62817383e-02,  3.22357178e-02,\n",
       "        5.42648315e-02, -8.20922852e-03,  2.46093750e-02,  5.67214966e-02,\n",
       "        3.28277588e-02,  5.88661194e-02,  5.65124512e-02, -5.89935303e-02,\n",
       "        3.78143311e-02, -2.20428467e-02, -2.69104004e-02, -4.51019287e-02,\n",
       "       -3.44680786e-02,  2.66296387e-02, -1.31291199e-01,  5.08392334e-02,\n",
       "        7.97882080e-02,  4.68252182e-02, -6.75552368e-02, -3.16894531e-02,\n",
       "       -4.02118683e-02,  2.93376923e-02,  6.84539795e-02,  7.23510742e-02,\n",
       "        4.07104492e-02,  5.87463379e-03,  4.83856201e-02, -4.79354858e-02,\n",
       "       -6.53808594e-02, -1.27053833e-01, -3.54675293e-02, -1.05542183e-02,\n",
       "        5.08880615e-02,  1.85623169e-03,  7.54516602e-02,  4.00173187e-02,\n",
       "       -7.39982605e-02, -2.59399414e-03, -3.69537354e-02, -1.40319824e-02,\n",
       "        4.13818359e-02, -6.62536621e-03, -6.19049072e-02,  2.27813721e-03,\n",
       "       -8.37524414e-02,  3.23608398e-02,  9.98535156e-03, -5.28717041e-03,\n",
       "       -3.65966797e-02, -5.57174683e-02,  1.15692139e-02, -1.70898438e-03])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bad_wv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.20289025e-02,  1.14652194e-02,  5.94764123e-02,  1.12267127e-01,\n",
       "       -2.35877404e-02,  3.07203440e-02,  1.44418570e-02, -1.38038048e-01,\n",
       "        3.64473783e-02,  1.40596243e-01, -9.13837139e-02, -1.62250225e-01,\n",
       "       -2.34175462e-02,  1.63762019e-02, -2.16533954e-02,  6.52547983e-02,\n",
       "       -1.67001578e-02,  9.54402043e-02,  3.67431641e-02, -4.39265325e-02,\n",
       "       -1.90241887e-02,  2.05136813e-02,  7.12421124e-02, -2.28107159e-02,\n",
       "       -2.36440805e-02,  8.81723257e-03, -1.01975661e-01,  8.71722882e-02,\n",
       "        3.81446252e-02,  7.61718750e-02,  2.53389799e-02,  5.92839168e-02,\n",
       "        4.80393630e-02, -3.06493319e-02,  4.03864934e-02,  9.37822782e-02,\n",
       "       -5.32367413e-02,  5.92510517e-03,  1.29077618e-01,  1.08022837e-01,\n",
       "        2.12026743e-02, -6.40373230e-02,  4.33819111e-02,  5.17859826e-03,\n",
       "       -2.51277043e-02, -2.43665255e-02,  5.23399940e-02,  1.89208984e-03,\n",
       "       -1.28220778e-02,  4.62380923e-02, -3.13415527e-02,  9.70599835e-02,\n",
       "       -3.03790753e-02,  6.47911659e-03,  1.80875338e-02,  2.12871845e-02,\n",
       "       -5.12507512e-02, -6.71856220e-03,  2.51206618e-02, -3.63440880e-02,\n",
       "       -6.34202224e-02,  5.96829928e-02, -8.38376559e-02, -6.70072115e-02,\n",
       "       -6.19882437e-02, -1.91321740e-02, -7.75146484e-03, -5.68918081e-03,\n",
       "       -4.88891602e-02,  4.94079590e-02,  7.15308556e-02,  5.97909781e-02,\n",
       "       -1.62916917e-03, -7.53079928e-03, -9.08672626e-02,  3.48364023e-02,\n",
       "        5.73636569e-02,  3.41233474e-02, -3.33345853e-02,  8.49891076e-02,\n",
       "       -1.11459585e-02, -8.50078876e-02,  6.73734225e-02, -6.98383038e-02,\n",
       "       -4.98140775e-03, -4.10291232e-02, -9.80975811e-02,  7.59969858e-02,\n",
       "        4.62552584e-02,  1.38162466e-02, -1.47869404e-02, -7.19980093e-03,\n",
       "       -2.52532959e-02, -3.30857497e-02, -6.94298377e-02,  3.23181152e-02,\n",
       "        2.35865666e-02,  5.90069111e-02,  3.17570613e-02,  2.56042480e-02,\n",
       "       -1.15886982e-01, -9.41819411e-02,  9.05104417e-02,  1.17844802e-03,\n",
       "       -1.89302885e-02, -4.27727332e-02, -3.06208684e-02,  2.07840846e-02,\n",
       "        5.26029147e-02, -5.60326209e-02, -4.86966647e-02, -3.48604642e-02,\n",
       "       -2.07050030e-03, -1.37892503e-02,  2.88473276e-02,  5.38423978e-02,\n",
       "        7.01669546e-02, -1.71520527e-02,  4.81966459e-02,  1.07398400e-02,\n",
       "       -5.44057993e-02, -3.43299279e-02, -6.54296875e-02,  3.11326247e-02,\n",
       "        5.86876502e-03, -2.61042668e-02, -8.12330980e-02,  2.36980732e-02,\n",
       "        9.85952524e-03, -4.72905086e-03, -4.73538912e-02, -1.08126127e-01,\n",
       "       -6.73264724e-03, -1.76016001e-02, -3.98395245e-02, -4.09358098e-02,\n",
       "        1.10426683e-02,  1.25826322e-03, -1.68341123e-02,  1.96791429e-02,\n",
       "        8.83976863e-02, -7.65099159e-02,  3.71633676e-02,  2.11275541e-03,\n",
       "       -6.72587982e-04, -1.05637770e-02, -7.42938702e-02, -3.61375075e-02,\n",
       "       -3.14190204e-02, -1.95124700e-02,  1.32378211e-01, -2.17519907e-02,\n",
       "       -1.29094050e-01,  2.62662447e-02, -9.75529597e-02, -2.97194261e-02,\n",
       "        1.10130897e-01, -5.19080529e-02, -7.33947754e-02, -4.31189904e-02,\n",
       "       -2.80433068e-02, -1.70616737e-02,  3.49901639e-02, -9.20222356e-03,\n",
       "        4.87717849e-02, -1.25967172e-01,  7.92987530e-02, -1.04039119e-01,\n",
       "       -3.90859751e-02,  1.02539062e-02, -1.42352764e-01, -5.38107065e-03,\n",
       "       -3.23627178e-02, -6.05327900e-02, -2.52169096e-02, -6.52184120e-02,\n",
       "        7.48291016e-02, -8.06978666e-02,  3.62642728e-02, -5.45677772e-03,\n",
       "        5.76547476e-03, -4.82142522e-02,  5.49245981e-02,  2.15430627e-02,\n",
       "       -5.13035701e-02,  5.11496617e-02, -7.36412635e-02,  9.28039551e-02,\n",
       "        1.28756010e-01,  2.14702900e-02,  1.25174889e-01,  6.72325721e-02,\n",
       "       -1.24065693e-02,  2.16440054e-03,  3.29026442e-02,  4.57951472e-02,\n",
       "       -8.28575721e-02,  3.69403546e-02, -5.97528311e-02, -1.13839956e-01,\n",
       "        5.89224008e-03,  2.96889085e-02, -4.10813552e-02, -2.04890325e-02,\n",
       "       -1.25779372e-02, -5.63401442e-05, -2.72357647e-02, -8.67931659e-02,\n",
       "       -1.40991211e-02,  2.68179087e-02,  1.69630784e-02,  6.84251052e-02,\n",
       "       -2.67052284e-02,  1.69583834e-02, -6.92455585e-02,  1.09610924e-02,\n",
       "        6.23708872e-02,  3.00574669e-02, -1.98035607e-02,  4.08360408e-02,\n",
       "       -2.83743051e-02, -1.79114709e-02,  4.85214820e-02, -2.15313251e-02,\n",
       "       -1.32634090e-04, -5.74481671e-02,  5.91195913e-02,  9.82290415e-02,\n",
       "       -7.64347957e-03,  9.05198317e-03, -7.51201923e-04, -6.89439040e-02,\n",
       "        5.67720853e-02,  5.48753005e-02, -6.61797157e-02,  1.06858474e-02,\n",
       "       -3.89286922e-02, -1.21571467e-02,  5.40137658e-02,  1.06107272e-01,\n",
       "        1.18633564e-01,  5.63166692e-03, -1.86016376e-02, -7.84489558e-02,\n",
       "       -5.04432091e-02,  9.00573730e-02, -1.97753906e-02,  8.90080379e-02,\n",
       "        1.20755709e-02, -3.08743990e-02,  4.92788462e-02,  4.59524301e-02,\n",
       "        7.06881010e-02,  3.19894644e-02,  8.04678110e-02, -1.71649639e-02,\n",
       "        1.46014874e-03,  4.86872746e-02, -9.46514423e-03, -2.34938401e-02,\n",
       "        4.36823918e-02, -1.44230769e-02,  1.01616199e-02,  1.23244066e-03,\n",
       "        4.61989183e-02,  1.91281832e-01,  3.01701472e-02, -1.79044283e-02,\n",
       "       -2.16158353e-02, -7.53908891e-03, -1.04980469e-02,  3.28744742e-02,\n",
       "        5.06028395e-02,  2.50737117e-02,  5.64011794e-02, -1.18718074e-01,\n",
       "        1.61273663e-02, -1.48888221e-01, -1.08492338e-01, -2.71606445e-03,\n",
       "       -1.67330228e-02, -6.55893179e-02,  4.20297476e-02,  1.27913255e-01,\n",
       "        2.12214543e-02, -7.97729492e-02, -1.30857614e-01,  2.16891949e-02,\n",
       "        6.93171575e-02, -7.32774001e-02, -7.65721248e-02,  2.77240460e-03,\n",
       "       -9.36232347e-02, -5.74669471e-03,  3.58980619e-02,  1.70405461e-02,\n",
       "       -1.93152794e-02, -5.78730657e-02, -1.55123197e-02, -4.82459435e-02])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_good_wv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5261903431382597"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([x_bad_wv[0]], [x_good_wv[0]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_similar = 0\n",
    "indx = 0\n",
    " \n",
    "sent_list = []\n",
    "\n",
    "for i in range(len(good_comments)):\n",
    "    sent_list.append((i, cosine_similarity([x_bad_wv[0]], [x_good_wv[i]])[0][0]))\n",
    "    # if cosine_similarity([x_bad_wv[0]], [x_good_wv[i]])[0][0] > max_similar:\n",
    "    #     max_similar = cosine_similarity([x_bad_wv[0]], [x_good_wv[i]])[0][0]\n",
    "    #     indx = i\n",
    "\n",
    "# print(indx, max_similar)\n",
    "sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python program to sort a list of tuples by the second Item\n",
    "  \n",
    "# Function to sort the list of tuples by its second item\n",
    "  \n",
    "  \n",
    "def Sort_Tuple(tup): \n",
    "  \n",
    "    # reverse = None (Sorts in Ascending order) \n",
    "    # key is set to sort using second element of \n",
    "    # sublist lambda has been used \n",
    "    tup.sort(key = lambda x: x[1]) \n",
    "    return tup \n",
    "  \n",
    "  \n",
    "# Driver Code\n",
    "  \n",
    "sorted_list = Sort_Tuple(sent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19275, 0.793549910664419),\n",
       " (19969, 0.7960331177452454),\n",
       " (18716, 0.7965489076563084),\n",
       " (9730, 0.8011442266448724),\n",
       " (9984, 0.8020099049361524),\n",
       " (16508, 0.8038161591069598),\n",
       " (9690, 0.8067328679938854),\n",
       " (9931, 0.8120637785688658),\n",
       " (20497, 0.8130163622612663),\n",
       " (15091, 0.8240306686920722)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And none of this white-collar resort prison. They should go straight to federal pound them in the ass prison.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And not white collar golfing prison either. They need to be in general population.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_comments[15091]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7564c074f31accd314b76e75d557053f2db515971302aea3335cc481b5057884"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
