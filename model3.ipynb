{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "\n",
    "# load pre-trained model and tokenizer\n",
    "model_name = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# example text to classify\n",
    "text = \"Hello, my name is John Smith.\"\n",
    "\n",
    "# tokenize text\n",
    "tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "\n",
    "# run model on tokens\n",
    "input_ids = torch.tensor([tokens])\n",
    "outputs = model(input_ids)\n",
    "\n",
    "# get predicted labels for each token\n",
    "predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
    "\n",
    "# map predictions back to tokens\n",
    "predicted_labels = [tokenizer.decode([p]) for p in predictions[1:-1]]\n",
    "\n",
    "# print results\n",
    "print(predicted_labels)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
